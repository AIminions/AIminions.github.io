---
layout: single
title: "백엔드와 모델링, 그리고 데이터 균형에 대한 깨달음"
date: 2025-06-03
categories: [프로젝트]
tags: [백엔드, 모델링, 데이터불균형, MS AI School]
header:
  overlay_image: /assets/images/aischool.jpg
  teaser: /assets/images/aischool.jpg
  caption: "AI school 로고"
---

<style>
/* ─── 썸네일 크기 조절 ───────────────────────────── */
.page__hero--overlay {
  height: 200px !important;           /* 원하는 높이(px)로 조절 */
  background-size: contain !important;/* 이미지 비율 유지하면서 축소 */
  background-position: center center;
}
</style>

오랜만의 기록, 공휴일의 작업

블로그에 마지막으로 글을 쓴 게 벌써 5월 12일이었네요. 오늘은 대통령 공휴일이지만, 프로젝트 일정이 빡빡해 팀원 한 분과 함께 백엔드 작업을 이어가고 있습니다.

원래 저는 모델링 담당이지만 MVP 일정이 지났음에도 아직 미완성이라서서 백엔드 개발이 급선무가 되었습니다. 긴급한 일정을 맞추기 위해, MVP 완성 전까지는 백엔드에 집중하기로 했습니다.

---

# 백엔드 작업 현황

현재 프로젝트 백엔드 개발은 Azure 기반으로 이루어지고 있으며, API 엔드포인트 구성, 데이터베이스 연결 및 데이터 처리 로직 구현 등의 작업이 진행 중입니다.

하지만 예상했던 것보다 더 많은 시간이 소요되고 있습니다. 특히 데이터 처리 파이프라인 부분에서 몇 가지 이슈들이 발생했고, 이를 해결하는 과정에서 많은 학습이 있었습니다.  
자세한 사항은 프로젝트 폴더 내의 백엔드 코드와 문서를 참고해주시면 됩니다.

백엔드 작업을 하면서 가장 크게 느낀 점은, 역시나 **백엔드는 프론트엔드와 모델 사이에서 끊임없이 소통하고 중재해야 하는 위치**라는 점이었습니다. 개발 과정에서 협업과 소통의 중요성을 다시 한번 절감하고 있습니다.

---

# 모델링 과정에서의 큰 깨달음: 데이터 불균형 문제 해결

최근 본격적으로 모델링 작업에 들어갔고, 특히 데이터 불균형 문제로 인해 고민이 많았습니다. 그 과정에서 **언더샘플링(Undersampling)** 을 적용하며 F₂ 점수가 크게 높아졌는데, 이 현상을 명확히 분석해보면서 많은 것을 깨달았습니다.

### 1. 클래스 불균형 완화 효과

- 원본 데이터에서 화재(양성)와 비화재(음성)의 비율은 약 **1 : 1382** 로 극심한 불균형을 보였습니다.
- 이 환경에서는 모델이 "거의 무조건 음성"을 예측해도 Accuracy가 높게 나왔지만, Precision이 1~2%에 그쳐 사실상 활용 불가능한 수준이었습니다.
- 하지만 언더샘플링으로 음성 데이터를 소수 클래스의 5배인 **1 : 5**로 조정하니, 모델이 양성 신호를 훨씬 자주 접하면서 화재 패턴을 더 잘 학습할 수 있었습니다.

### 2. Precision과 Recall의 동시 개선

- 결과적으로 Precision이 0.61, Recall이 0.94라는 놀라운 성과를 얻었습니다.
- 원본 환경 대비 Precision이 60% 이상 급상승하면서 거짓 경보(False Positive)가 극적으로 줄었고, 동시에 Recall 또한 높아져, 결국 **F₂ 점수가 0.85까지 상승**했습니다.

### 3. Threshold 최적화의 효과

- Threshold를 0.2323 정도로 설정했을 때 F₂ 점수가 최대였습니다.
- 기존 불균형 환경에서는 threshold 최적점을 찾기가 어려웠으나, 균형 잡힌 데이터를 통해 양성 확률 분포가 개선되면서 최적의 threshold 설정이 가능해졌습니다.

### 4. 파라미터 튜닝의 변화

- 언더샘플링을 적용하니, 불균형 보정을 위한 하이퍼파라미터(scale_pos_weight 등)의 부담이 줄고, 모델이 소수 클래스 학습에 온전히 집중할 수 있게 되었습니다.
- 덕분에 모델이 더 깨끗하고 선명한 패턴을 잡아낼 수 있게 되었습니다.

### 📌 종합적 결론

- 데이터 불균형 문제를 해결함으로써, 모델이 화재 탐지(Recall)와 거짓 경보 감소(Precision)를 동시에 달성했습니다.
- Threshold 설정과 파라미터 튜닝의 효율성도 크게 개선되어, 결과적으로 F₂ 중심의 모델 평가 기준에서 훨씬 좋은 성능을 얻었습니다.

이번 실험을 통해 알게 된 것은 데이터 전처리와 균형이 모델 성능에 얼마나 큰 영향을 주는지에 대한 확실한 인사이트였습니다. "모델링이란 결국 데이터를 어떻게 잘 다루느냐의 문제"라는 말을 다시 한번 깊게 이해했습니다.

---

# 마무리

공휴일에도 불구하고 백엔드와 모델링 작업을 병행하며 바쁘게 시간을 보내고 있습니다.

앞으로는 프로젝트 기록보단 기술적 통찰, 스택 위주로 적을까 합니다. 그게 취업에도 도움이 더 될테니..

다음에 또 뵙겠습니다.
